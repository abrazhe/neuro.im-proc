---
jupyter:
  jupytext:
    formats: ipynb,Rmd
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.14.4
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

<!-- #region toc=true -->
<h1>Table of Contents<span class="tocSkip"></span></h1>
<div class="toc"><ul class="toc-item"><li><span><a href="#Next-actions-and-TODOs" data-toc-modified-id="Next-actions-and-TODOs-1"><strong>Next actions and TODOs</strong></a></span></li><li><span><a href="#Параметры-для-запуска" data-toc-modified-id="Параметры-для-запуска-2">Параметры для запуска</a></span></li><li><span><a href="#Считывание-изображения" data-toc-modified-id="Считывание-изображения-3">Считывание изображения</a></span></li><li><span><a href="#Предобработка-изображения" data-toc-modified-id="Предобработка-изображения-4">Предобработка изображения</a></span><ul class="toc-item"><li><span><a href="#CLAHE" data-toc-modified-id="CLAHE-4.1">CLAHE</a></span></li><li><span><a href="#Кадрирование" data-toc-modified-id="Кадрирование-4.2">Кадрирование</a></span></li><li><span><a href="#Масштабирование" data-toc-modified-id="Масштабирование-4.3">Масштабирование</a></span></li><li><span><a href="#Фильтрация-изображения" data-toc-modified-id="Фильтрация-изображения-4.4">Фильтрация изображения</a></span></li></ul></li><li><span><a href="#Сегментация-сомы" data-toc-modified-id="Сегментация-сомы-5">Сегментация сомы</a></span><ul class="toc-item"><li><span><a href="#Определение-центра" data-toc-modified-id="Определение-центра-5.1">Определение центра</a></span></li><li><span><a href="#Выделение-сомы" data-toc-modified-id="Выделение-сомы-5.2">Выделение сомы</a></span></li></ul></li><li><span><a href="#Расчет-матрицы-Гессе-для-различных-сигм" data-toc-modified-id="Расчет-матрицы-Гессе-для-различных-сигм-6">Расчет матрицы Гессе для различных сигм</a></span></li><li><span><a href="#Расчет-масок-для-различных-сигм" data-toc-modified-id="Расчет-масок-для-различных-сигм-7">Расчет масок для различных сигм</a></span></li><li><span><a href="#Объединение-результатов-Сато-для-различных-сигм" data-toc-modified-id="Объединение-результатов-Сато-для-различных-сигм-8">Объединение результатов Сато для различных сигм</a></span></li><li><span><a href="#Объединение-собственных-векторов-различных-сигм" data-toc-modified-id="Объединение-собственных-векторов-различных-сигм-9">Объединение собственных векторов различных сигм</a></span></li><li><span><a href="#Построение-графа" data-toc-modified-id="Построение-графа-10">Построение графа</a></span><ul class="toc-item"><li><span><a href="#Выражение-для-весов-ребер" data-toc-modified-id="Выражение-для-весов-ребер-10.1">Выражение для весов ребер</a></span></li><li><span><a href="#Добавление-точек-оболочки-сомы-в-граф" data-toc-modified-id="Добавление-точек-оболочки-сомы-в-граф-10.2">Добавление точек оболочки сомы в граф</a></span></li></ul></li><li><span><a href="#Расчет-путей,-встречаемости-точек-в-путях-и-слияние-графов-по-путям" data-toc-modified-id="Расчет-путей,-встречаемости-точек-в-путях-и-слияние-графов-по-путям-11">Расчет путей, встречаемости точек в путях и слияние графов по путям</a></span><ul class="toc-item"><li><span><a href="#Building-all-paths-at-once,-using-the-&quot;best-scale&quot;-full-graph" data-toc-modified-id="Building-all-paths-at-once,-using-the-&quot;best-scale&quot;-full-graph-11.1">Building all paths at once, using the "best-scale" full graph</a></span></li><li><span><a href="#Converting-paths-to-directed-graphs,-merging-and-visualizing-the-graphs" data-toc-modified-id="Converting-paths-to-directed-graphs,-merging-and-visualizing-the-graphs-11.2">Converting paths to directed graphs, merging and visualizing the graphs</a></span></li></ul></li><li><span><a href="#Добавление-сопутствующей-информации" data-toc-modified-id="Добавление-сопутствующей-информации-12">Добавление сопутствующей информации</a></span></li><li><span><a href="#Распределения-встречаемостей-по-сигме" data-toc-modified-id="Распределения-встречаемостей-по-сигме-13">Распределения встречаемостей по сигме</a></span></li><li><span><a href="#Расстояния-между-узлами" data-toc-modified-id="Расстояния-между-узлами-14">Расстояния между узлами</a></span><ul class="toc-item"><li><span><a href="#Визуализация" data-toc-modified-id="Визуализация-14.1">Визуализация</a></span></li></ul></li><li><span><a href="#Сохранение" data-toc-modified-id="Сохранение-15">Сохранение</a></span></li></ul></div>
<!-- #endregion -->

<!-- #region -->
# **Next actions and TODOs**


## Current: 
Now I'm trying to look a filamentous skeletons of the cells based on the ideas in projected gradient approach, i.e. that if $g(x)$ is our intensity gradient (at some scale $\sigma$), and ${\lambda_i}, {v_i}$ are (sorted $\lambda_1 > \lambda_2, ...$) eigenvalues and eigenvectors of the Hessian (at the same scale $\sigma$), then let $V=[v_2,...,v_d]$ we are searching for $G(x) =  VV^T g(x)= 0$. Because looking just for small values of $G$ might be not what we need, searching for places where $G$ changes its sign would be more efficient (probably).

Была проблема в том, что точки сначала сходились к филаментам, потом вдоль образовавшихся тяжей пытались убежать из некоторых мест, фрагментируя скелет. 

Более-менее рабочее решение заключается в том, чтобы перед расчетом траекторий построить k-NN граф из точек и в векторы, смещающие точки вдоль проекций градиента добавить еще смещение к соседям. Это позволяет "противостоять" векторному полю, если оно пытается растащить точки в разные стороны, оставив пустое место.

### **TODO:** (что дальше нужно попробовать)
- [ ] Убедиться, что стандартный набор параметров примерно одинаково работает на разных sigma
- [ ] Чему должно быть равно число соседей для оптимального результата (одинаково для разных сигма)?
  - [ ] попробовать разное kNN -> сравнить результат
- [ ] Что можно проконтролировать, меняя density_rad (равновесное расстояние между соседями)?
  - [ ] Попробовать density_rad = {0, 0.1, 0.5, 1.0} -> что будет отличаться?

- [ ] Можно ли добиться лучшего результата, если сделать процесс двухступенчатым: после первых N~300 итераций остановиться, возможно уменьшить количество точек (см `merge_points()` `density_filter()`), заново перестроить k-NN граф и сделать еще один прогон. Возможно, это позволит уменьшить jitter около точек ветвления и в других местах, где алгоритм изначально не сжимался в узкий тяж.
  - [ ] поработать с парой `density_filter()` ,`merge_points()` -> улучшайзинг скелета после первого прогона
  - [ ] Попробовать запустить второй прогон, используя на входе (улучшенные) результаты первого
- [ ] Сравнить результаты на разных масштабах --> можно ли потом объединить разные скелеты? Например, выбирая точки, для которых данный масштаб является оптимальным?
  - [ ] Вывести на одном изображении скелеты для набора масштабов (пусть sigma =[1.5, 3, 6, 12])
- [ ] Подумать, как объединить с предыдущим подходом (пути dijkstra). Возможно, строить пути до ближайшей точки скелета? И отдельно по скелету до сомы? Или другие идеи?
- [ ] Попробовать применить к другим клеткам

## Previous:
In this notebook I introduce that we drop rescaling in Z-axis (but the distances will get screwed up and need to be rescaled).

Also, frustrated by "branch jumping", I decided to take another go at iterative building of paths, from large sigmas to smaller ones. It did take a hell lot of a time, but now it seems to work (well, at least performs better than building the paths at one go).

 - [ ] Test performance on other cells
 - [ ] Test performace of the approach with more sigma steps (log scale is preferred, i.e. `2.0**np.arange(-1,5,0.5)`)
 - [ ] Think about a way to regularize vector orientations, using orientations of the neighbours, or at different scales
 - [-] Find a best way to skeletonize the qstack-based arrays and masks (as one of the approaches)
 - [X] Find a way to "glue" together paths, that a close-by and have a similar direction
 - [ ] Visualize different sub-trees in the merged paths (add individually to napari?)
 - [ ] add way to gradually strip/simplify (sub-)graphs for better visualization
 
<!-- #endregion -->

```{python}
import os
import sys
```

```{python}
# %matplotlib inline
```

```{python}
import matplotlib.pyplot as plt
```

```{python}
import cv2
```

```{python}
from functools import reduce
import operator as op
```

```{python}
from importlib import reload
```

```{python}
import scipy
from scipy import ndimage as ndi
import numpy as np
import networkx as nx

from pathlib import Path
```

```{python}
import napari
```

```{python}
import scipy as sp
```

```{python}
#import xarray
```

```{python}
from tqdm.auto import tqdm
```

```{python}
import ccdb
import astromorpho as astro
```
```{python}
from networx2napari import draw_edges, draw_nodes
```
```{python}
import graph_utils as gu  
import visualization as vis
```

```{python}
def eu_dist(p1, p2):
    return np.sqrt(np.sum([(x - y)**2 for x, y in zip(p1, p2)]))
```


```{python}

```

```{python}
def get_shell_mask(mask, do_skeletonize=False, as_points=False):
    out = ndi.binary_erosion(mask)^mask
    if do_skeletonize:
        out = skeletonize(out)
    if as_points:
        out = astro.morpho.mask2points(out)
    return out 
```

```{python}
from skimage.filters import threshold_li, threshold_minimum, threshold_triangle
from skimage.morphology import remove_small_objects
```

```{python}
def largest_region(mask):
    labels, nlab = ndi.label(mask)
    if nlab > 0:
        objs = ndi.find_objects(labels)
        sizes = [np.sum(labels[o]==k+1) for k,o in enumerate(objs)]
        k = np.argmax(sizes)
        return labels==k+1
    else:
        return mask
        
def crop_image(img, mask=None, margin=0, min_obj_size=0):
    if mask is None:
        mask = img > 0
    if min_obj_size > 0:
        mask = remove_small_objects(mask, min_obj_size)
    if margin > 0:
        mask = ndi.binary_dilation(mask, iterations=margin)
    objs = ndi.find_objects(mask)
    min_bnds = np.min([[sl.start for sl in o] for o in objs],0)
    max_bnds = np.max([[sl.stop for sl in o] for o in objs],0)
    crop = tuple(slice(mn,mx) for mn,mx in zip(min_bnds, max_bnds))
    return img[crop]
```

```{python}
plt.rc('figure', dpi=150)
```

# Параметры для запуска

```{python tags=c("parameters")}
if os.path.exists('/home/brazhe/yandex-disk/'):
    data_dir = '/home/brazhe/yandex-disk/data-shared-comfi/3D-astrocyte-images/selected-for-complexity/'

elif os.path.exists('/home/levtg/astro-morpho'):
    data_dir = '/home/levtg/astro-morpho/data/'
else:
    print("Dont know where to look for the data")

filename = '3wk-both1-grn-raw.pic' # Test cell AKA "Good fella"
#filename = '4wk-ly9-raw.pic' # Octopus
# filename = '2020-12-30 WT1 18month slice1-3 hippo CA1 SR astrocyte lucifer yellow 60X zoom2,5.tif'
#filename = '3wk-ly1-raw.pic' # Cell-killer

use_clahe = True
sigmas = np.arange(0.5, 8, 0.5)

verbose = True

# Set false to start from console
HANDY = True

# Set true to save output
OUT = False
```

```{python}
filepath = Path(data_dir).joinpath(filename)
filepath
```

# Считывание изображения

```{python}
if HANDY:
    verbose = False
#     filename = '/home/levtg/astro-morpho/data/3wk-ly10-raw.pic'
```

```{python}
stack, meta = ccdb.read_pic(filepath)
dims = ccdb.get_axes(meta)
dims
```

```{python}
if len(dims):
    zoom = (dims[-1][0]/dims[0][0])
else:
    zoom = 4
    
print(zoom)
```

```{python}
stack.shape
```

Странно, неужели у нас эти данные (`.pic`) были в uint8 формате все это время?

```{python}
stack.dtype
```

```{python}

```

# Предобработка изображения


## CLAHE
In fact, I don't know if we really need this or indeed it can  be replaced by e.g. retinex or multiscale retinex. 

```{python}
clahe = cv2.createCLAHE(clipLimit =2.0, tileGridSize=(8,8))
```

```{python}
stack_shape = stack.shape
img_clahe = np.zeros(stack.shape, np.float32)
for k,plane in enumerate(stack):
    img_clahe[k] = clahe.apply(plane)
```

```{python}
if verbose:
    wi = napari.view_image(stack, ndisplay=3, scale=(zoom, 1,1), name='raw', colormap='magenta')
    wi.add_image(img_clahe, scale=(zoom,1,1), name='CLAHE',colormap='magenta')
```

```{python}
plt.figure()
plt.hist(np.ravel(stack), 100, histtype='step', log=True, label='raw');
plt.hist(np.ravel(img_clahe), 100, histtype='step', log=True, label='CLAHE');
plt.title("Effect of CLAHE on stack histogram")
plt.legend()
```

```{python}
# check if use clahe or not
img = img_clahe if use_clahe else stack
```

## Кадрирование

```{python}
max_proj = img.max(0)
```

```{python}
domain_mask = ndi.binary_dilation(largest_region(remove_small_objects(max_proj > 0.5*threshold_li(max_proj))), iterations=3)
domain_mask = ndi.binary_closing(domain_mask,iterations=3)
```

```{python}
plt.imshow(max_proj, cmap='gray')
plt.contour(domain_mask, colors=['r'], levels=[0.5])
```

```{python}
img_cropped = np.array([crop_image(plane,domain_mask, margin=10) for plane in img])
```

```{python}
max_proj_1 = img_cropped.max(1)
domain_mask_1 = ndi.binary_dilation(largest_region(remove_small_objects(max_proj_1 > 0.5*threshold_li(max_proj_1))), iterations=3)
domain_mask_1 = ndi.binary_closing(domain_mask_1,iterations=3)
plt.imshow(max_proj_1, cmap='gray')
plt.contour(domain_mask_1, colors=['r'], levels=[0.5])
```

```{python}
img_cropped = np.array([crop_image(img_cropped[:,i],domain_mask_1, margin=10) for i in range(img_cropped.shape[1])]).swapaxes(0,1)
```

```{python}

```

```{python}
if verbose:
    w = napari.view_image(img_cropped)
```

## Масштабирование


Важный вопрос, как сделать одинаковым масштаб по осям z и xy. Можно downsample XY, можно upsample (by interpolation) Z. Можно комбинировать. В этом ноутбуке проверяем, что будет, если не делать пересэмплирование по Z. Но делаем downsampling по X,Y

```{python}
downscale = 2
# #%time img_noisy = ndi.zoom(img_cropped.astype(np.float32), (zoom/downscale, 1/downscale, 1/downscale), order=1)
img_noisy = ndi.zoom(img_cropped.astype(np.float32), (1, 1/downscale, 1/downscale))
```

```{python}
scale = (zoom/downscale, 1, 1)
print(scale)
if verbose:
    napari.view_image(img_noisy, scale=scale)
```

```{python}
plt.imshow(img_noisy.max(0), cmap='gray')
```

```{python}
img.shape, img_noisy.shape
```

```{python}
# img_noisy = img_cropped
```

## Фильтрация изображения

```{python}
def filter_image(image, filter_func):
    threshold = filter_func(image)
    #img_filt = np.where(image > threshold, image, 0)
    pre_mask = ndi.binary_closing(image >= 0.9*threshold)
    pre_mask = remove_small_objects(pre_mask, 5, connectivity=3)
    binary_clean = largest_region(pre_mask)
    return np.where(binary_clean, image, 0)
```

```{python}
img_clear = filter_image(img_noisy, threshold_li)
```

```{python}
final_image = img_clear
final_image.shape
```

```{python}
domain_mask3d = ndi.binary_fill_holes(final_image > 0)
domain_shell_mask = get_shell_mask(domain_mask3d)
```

```{python}
def planewise_fill_holes(mask):
    for k,plane in enumerate(mask):
        mask[k] = ndi.binary_fill_holes(plane)
    return mask

    
domain_mask3d = planewise_fill_holes(domain_mask3d)

domain_mask3d = np.moveaxis(domain_mask3d, 1, 0)   
domain_mask3d = planewise_fill_holes(domain_mask3d)
domain_mask3d = np.moveaxis(domain_mask3d, 0, 1)


domain_mask3d = np.moveaxis(domain_mask3d, 2, 0)
domain_mask3d = planewise_fill_holes(domain_mask3d)
domain_mask3d = np.moveaxis(domain_mask3d, 0, 2)
```

```{python}
domain_outer_shell_mask = get_shell_mask(domain_mask3d) & domain_shell_mask
```

```{python}
if verbose:
    w = napari.view_image(img_noisy)
    w.add_image(final_image, colormap='magenta', blending='additive')
    w.add_image(domain_shell_mask, colormap='green', blending='additive')
    w.add_image(domain_outer_shell_mask, colormap='red', blending='additive')
```

# Сегментация сомы


## Определение центра

```{python}
import itertools as itt
```

```{python}
def percentile_rescale(arr, plow=1, phigh=99.5):
    low, high = np.percentile(arr, (plow, phigh))
    if low == high:
        return np.zeros_like(arr)
    else:
        return np.clip((arr-low)/(high-low), 0, 1)
```

```{python}
def flat_indices(shape):
    idx = np.indices(shape)
    return np.hstack([np.ravel(x_)[:,None] for x_ in idx])
```

```{python}
X1a = flat_indices(final_image.shape)
```

```{python}
# %time weights_s = percentile_rescale(np.ravel(ndi.gaussian_filter(final_image,5))**2,plow=99.5,phigh=99.99)
```

```{python}
center = tuple(map(int, np.sum(X1a*weights_s[:,None],axis=0)/np.sum(weights_s)))
center
```

## Выделение сомы

```{python}
from skimage.morphology import dilation, skeletonize, flood
```

```{python}
from astromorpho import morpho
```

**Альтернативный подход к сегментации сомы**
1. Работаем со сглаженным стеком
2. делаем первичную маску как flood из центра с толерантностью в 10% разницы между максимальным и минимальным значениями в стеке
3. Разрастаем (аналог flood) первичную маску в несколько итераций

```{python}
#soma_mask = largest_region(np.where(dilation(eroded), True, False))
#soma_mask = largest_region(final_image >= np.percentile(final_image, 99))

smooth_stack = ndi.gaussian_filter(final_image, 3)
tol = (smooth_stack.max() - smooth_stack[final_image>0].min())/10

print('tol:',tol)
# %time soma_seed_mask = flood(smooth_stack, center, tolerance=tol)
```

```{python}
# %time soma_mask = morpho.expand_mask(soma_seed_mask, smooth_stack, iterations = 10)
```

```{python}
#verbose=True
```

```{python}
if verbose:
    w = napari.view_image(final_image, ndisplay=3, opacity=0.5)
    w.add_image(soma_seed_mask, blending='additive', colormap='cyan')
    w.add_image(soma_mask, blending='additive', colormap='magenta')
    
```

```{python}
# %time soma_shell = get_shell_mask(soma_mask, as_points=True)
```

# Проверяем, как работает выделение филаментов для одного пространственного масштаба

```{python}
def percentile_rescale(arr, plow=1, phigh=99):
    vmin,vmax = np.percentile(arr, (plow, phigh))
    if vmin == vmax:
        return np.zeros_like(arr)
    else:
        return np.clip((arr-vmin)/(vmax-vmin),0,1)
```

```{python}
def show_field2d(vfield, background=None, crop=None, weights=None, scale=25):
    
    
    fig, ax = plt.subplots(1,1,figsize=(9,9)); 
    
    if crop is None:
        crop=(slice(None,),slice(None))
    
    if background is not None:
        ax.imshow(background[crop], cmap='gray')
    
    V = -vfield[crop][...,0]# ROW (Y) directions; negative sign due to 'origin="upper" by default in imshow'
    U = vfield[crop][...,1]
        
    ax.quiver(U,V, weights[crop], scale=scale, cmap='inferno')
    return fig
```

```{python}
from skimage import feature as skf
import itertools as itt

_symmetric_image = (skf.corner._hessian_matrix_image if '_hessian_matrix_image' in dir(skf.corner)
                    else skf.corner._symmetric_image)


def hessian_by_dog(img, sigma, rel_scale=None, return_gradient=False,):
    ndim = np.ndim(img)
    if rel_scale is None:
        rel_scale = np.ones(ndim)
    ax_pairs = itt.combinations_with_replacement(range(ndim),2)
    sigma = sigma/np.sqrt(2)
    trunc = 6 # default
    if np.any(sigma*trunc < 3):
        trunc = 3/np.min(sigma)
    def dog(m,k):
        o = np.zeros(ndim, int)
        o[k] = 1
        g = ndi.gaussian_filter(m, sigma, order=o, truncate=trunc)
        return g#/rel_scale[k]**2
    
    double_dog = lambda axp: dog(dog(img, axp[0]),axp[1])
    out = [double_dog(axp) for axp in ax_pairs]
    if return_gradient:
        g = [dog(img, ax)/rel_scale[ax]**2 for ax in range(ndim)]
        return out, g
    else:
        return out



def hessian_eigen_decomp(H):
    #Hmat = skf.corner._hessian_matrix_image(H)
    # note we should ensure that eigenvalues in *descending* order
    # that is, in a bright filamentous structure the first eigenvalue should have small 
    # absolute value, while last eivenvalues should be negative and have large absolute 
    # value
    
    Hmat = _symmetric_image(H)
    w,v = np.linalg.eigh(Hmat)
    return w[...,::-1],v[...,::-1]


def barebone_sato(eigenvalues, gamma12=0.5, gamma23=0.5, alpha=0.25):

    lams = eigenvalues    
    
    lam1,lam2,lam3 = [lams[...,i] for i in range(3)]
    ratio1 = np.where(lam3!=0, lam2/(1e-6 + lam3),0)
    ratio2 = lam1/(1e-6 + np.abs(lam2))
    
    out = np.where(lam1 < 0, 
                   np.abs(lam3)*np.abs(ratio1)**gamma23*np.abs(1 + ratio2)**gamma12,
                   np.where((lam2 < 0) & (lam1 < np.abs(lam2)/alpha), 
                            np.abs(lam3)*np.abs(ratio1)**gamma23*np.abs(1 - alpha*ratio2)**gamma12,0))
    return out.astype(np.float32)
```

```{python}
def get_multi_vecs_interp(locs, field, order=1):
    locs = np.asarray(locs)
    dims = np.arange(field.shape[-1])
    return np.array([ndi.map_coordinates(field[...,i], locs.T, order=order) for i in dims]).T
```

```{python}
def project_points(points, stopped=None, img=None, ax=None,
                   alpha=0.25,
                   markersize=2,
                   figsize=(16,16)):
    if ax is None:
        fig, ax = plt.subplots(1,1, figsize=figsize)
        ax.axis('off')
        plt.tight_layout()
   
    if not len(ax.images) and img is not None:
        ax.imshow(img, cmap='gray')
    
    if not len(ax.lines):
        ax.plot(points[:,2],points[:,1], 'm.',markersize=markersize, 
                alpha=alpha)
        if stopped is not None:
            ax.plot(stopped[:,2],stopped[:,1], 'g.',markersize=1.5*markersize, 
                    alpha=alpha)
    else:
        lh = ax.lines[0]
        lh.set_data(points[:,2],points[:,1])
        if stopped is not None:
            if len(ax.lines) < 2:
                ax.plot(stopped[:,2],stopped[:,1], 'g.',
                        markersize=1.5*markersize, alpha=alpha)
            else:
                lh = ax.lines[1]
                lh.set_data(stopped[:,2],stopped[:,1])

    ax.figure.canvas.draw()
    return ax
```

```{python}
def calc_trajectory_basic(field, pts0, n_iter=10, tol=1e-3,
                          h=0.25,
                          with_plot=False,
                          plot_save_pattern=None,
                          save_interval=10,
                          gamma = 0.99):
    pts_prev = pts0
    
    img_proj = final_image.max(0)
    
    frozen = np.zeros(len(pts0), bool)
    stationary_counter = np.zeros(len(pts0), np.uint16)
    
    ax = None
        
    mult = 1.0
    for i in tqdm(range(n_iter)):
        vec = get_multi_vecs_interp(pts_prev, field)
        vec[frozen] = 0 # don't move points that are already considered converged
        
        pts = pts_prev + mult*h*vec
        
        delta = np.linalg.norm(pts-pts_prev, axis=1)
        stop_cond = (delta < tol) 
        stationary_counter[stop_cond] += 1
        frozen[stationary_counter > 5] = True

        if with_plot and not i%save_interval:
            ax = project_points(pts[~frozen], pts[frozen], img=img_proj, ax=ax)
            if plot_save_pattern is not None:
                ax.figure.savefig(plot_save_pattern.format(i=i))
        pts_prev = pts
        mult *= gamma
    return pts
```

```{python}
def calc_trajectory_multi2(field, pts0, n_iter=10, tol=1e-3, 
                          h=0.25, 
                          with_plot=False,
                          plot_save_pattern=None,
                          save_interval=10,
                          gamma = 0.99,
                          knn=6,
                          agg_alpha=0.1, 
                          density_rad = 0.1,
                          verbose=False):
    pts_prev = pts0
    stopped = []
    img_proj = final_image.max(0)
    ax = None
    
    mult = 1.0 # this is a multiplier used to attenuate force field over time
    frozen = np.zeros(len(pts0), bool)
    stationary_counter = np.zeros(len(pts0), np.uint16)
    vec_prev = None
    
    
    # establish nearest-neighbors at the beginning
    # number of neighbors could be a parameter
    kdt0 = sp.spatial.KDTree(pts_prev)
    nn_dists, nn_inds = kdt0.query(pts_prev, knn)
    
    for i in tqdm(range(n_iter)):
        vec = get_multi_vecs_interp(pts_prev, field)
        
        
        # -- this is what I'd do if I wanted new NN graph at each iteration
        #kdt1 = sp.spatial.KDTree(pts_prev)
        #nn1 = kdt1.query_ball_point(pts_prev, density_rad, return_length=True)
        
        # Trying to keep old-mates close:
        agg_force = (pts_prev[:,None,:] - pts_prev[nn_inds]).sum(1) - density_rad
        
        vec = vec - agg_alpha*agg_force
        vec[frozen] = 0 # don't move points that are already considered converged
        
        # simple adams-bashforth scheme
        if vec_prev is None:
            pts = pts_prev + h*mult*vec      
        else:
            pts = pts_prev + h*mult*(1.5*vec - 0.5*vec_prev)
        
        
        # count points that haven't moved much for 5 iterations as converged
        delta = np.linalg.norm(pts-pts_prev, axis=1)
        stationary_counter[delta < tol] += 1
        frozen[stationary_counter > 5] = True
        
        # make a  plot if needed
        if with_plot and not i%save_interval:
            ax = project_points(pts[~frozen], pts[frozen], img=img_proj, ax=ax)
            fig = ax.figure
            if plot_save_pattern is not None:
                fig.savefig(plot_save_pattern.format(i=i))

        # switch  states
        pts_prev = pts
        vec_prev = vec
        mult *= gamma
        
        # this condition can be made softer, i.e. break if 1% of points
        # remains unfrozen
        if np.all(frozen):
            break
    return pts
```

```{python}
# #np.where?
```

```{python}
# vec = get_multi_vecs_interp(pts, VVg)
# pts2 = pts + vec
# vec2 = get_multi_vecs_interp(pts2,VVg)
```

```{python}

```

```{python}
#vec.shape, vec2.shape
```

```{python}

```

```{python}
sigma = 2
```

```{python}
scale
```

**Thing to note:** new version of skimage seems to make a transition to calulating derivatives as gaussian derivatives instead of finite-difference operation on gaussian-smoothed image. Need to update my code accordingly, and find out which produces best results

```{python}
# %matplotlib inline
```

```{python}
sigma/scale[0], sigma,  sigma
```

```{python}
#astro.morpho.eigh
```

```{python}
astro.morpho.eigh = np.linalg.eigh
```

```{python}
# %time H,g  = hessian_by_dog(final_image, sigma=(sigma/scale[0],sigma,sigma), rel_scale=scale, \
#                             return_gradient=True) # RC order by default

g = sigma*np.stack(g,axis=3)
```

```{python}
# %time lams,Vf = hessian_eigen_decomp(H)
```

```{python}
# %time sato = barebone_sato(lams)
```

```{python}
threshold = threshold_li(sato[sato>0])*sigma**0.5
mask = remove_small_objects(sato > threshold, min_size=int(sigma*64))
```

```{python}
# # %%time 

# sato1, Vf1 = astro.morpho.sato3d(final_image, 
#                                  (sigma/scale[0], sigma,sigma), 
#                                  #hessian_variant='dog', 
#                                  do_brightness_correction=False, 
#                                  return_vectors=True)
```

```{python}
# Vf = Vf1
# sato = sato1
```

```{python}
# w = napari.view_image(final_image, opacity=0.7)
# w.add_image(sato, colormap='cyan',blending='additive')
# w.add_image(sato1, colormap='magenta', blending='additive')
```

```{python}
loc = (40,150,133)
```

```{python}
lams[loc]
```

```{python}
g[loc]
```

```{python}
# %time VV = np.einsum('...ij,...jk', Vf[...,1:], np.einsum('...ji', Vf[...,1:]))
```

```{python}
# #%time VV1 = np.einsum('...ij,...jk', Vf1[...,1:], np.einsum('...ji', Vf1[...,1:]))
```

```{python}
# %time VVg = np.einsum('...ij,...j->...i', VV, g)
```

```{python}
# #%time VVg1 = np.einsum('...ij,...j->...i', VV1, g)
```

```{python}
VVg_mag = np.linalg.norm(VVg,axis=-1)
VVg_sign = np.sign(np.sum(VVg,axis=-1))
VVg_mag_max = np.max(VVg_mag)
```

```{python}
pts = np.array(np.where(mask)).T
```

```{python}
pth = np.percentile(VVg_mag, 99)
VVg_clipped = VVg/pth
#cond = np.linalg.norm(VVg_clipped,axis=-1)>1
VVg_clipped[VVg_mag>pth] /= VVg_mag[VVg_mag>pth][:,None]/pth
```

```{python}
#VVg_clipped = np.where(VVg_mag > 1, VVg/VVg_mag[...,None], VVg)
```

```{python}
# %matplotlib qt
```

```{python}
kplane=40
show_field2d(VVg[kplane][...,1:]/VVg_mag.max()*mask[kplane][...,None], 
             final_image[kplane], scale=15, weights=sato[kplane])
```

```{python}
kplane=40
show_field2d(VVg_clipped[kplane][...,1:], 
             final_image[kplane], scale=50, weights=sato[kplane])
```

```{python}
project_points(pts, img=final_image.max(0))
ax = plt.gca()
ax.figure
```

```{python}
plt.close('all')
```

```{python}
domain_mask3d.shape
```

```{python}
#napari.view_image((~mask)^domain_mask3d)
```

```{python}
#VVg_mag2 = np.linalg.norm(VVg_clipped,axis=-1)
VVg_mag2 = VVg_mag/VVg_mag.max()
```

```{python}
plt.figure()
plt.hist(VVg_mag[mask],100,density=True);
plt.hist(VVg_mag[mask^domain_mask3d],100,density=True, histtype='step');
plt.title('sigma={}'.format(sigma))
plt.gcf()
```

```{python}
from numpy.linalg import norm
```

```{python}
plt.figure()
plt.hist(norm(VVg_clipped[mask],axis=-1),100,density=True,range=(0.,0.99));
plt.hist(norm(VVg_clipped[mask^domain_mask3d],axis=-1),100,density=True,
         range=(0,0.99),
         histtype='step');
plt.gcf()
```

```{python}
th_g = threshold_li(VVg_mag[mask^domain_mask3d])
th_g
```

```{python}
#np.percentile(VVg_mag[mask], 50)
```

```{python}
#VVg[VVg_mag2 < th_g] = 0
```

```{python}
plt.close('all')
```

```{python}
# #rm figures/filaments-*.png
```

```{python}
# %%time 
endpoints0 = calc_trajectory_basic(VVg_clipped,
                                  pts, 
                                  n_iter=500, 
                                  tol=0.001, 
                                  with_plot=True,
                                  save_interval=4,
                                  gamma=1.0,
                                  plot_save_pattern='figures/filaments-{i:04d}.png')
```

```{python}
# #rm figures/filaments-*.png
```

```{python}
#0.996**1000
```

```{python}
# %%time 
endpoints = calc_trajectory_multi2(VVg_clipped,
                                   pts, 
                                   n_iter=500, 
                                   tol=0.001, 
                                   with_plot=True,
                                   save_interval=1,
                                   gamma=1.0,
                                   knn=6,
                                   agg_alpha=0.25,
                                   plot_save_pattern='figures/filaments2-{i:04d}.png')
```

**ideas for future**
- [ ] utilize *weight* of points and grow it by merging
- [ ] add *springs* between points to stop them leaving nice spots. At each iteration make graph of 
      nearby points, add vector that tries to move the points to local mean value?

```{python}
plt.close('all')
```

```{python}
fig = plt.figure(figsize=(9,9))
ax = plt.gca()
ax.axis('off')
project_points(endpoints, img=final_image.max(0), ax=ax)
plt.tight_layout()
fig
```

```{python}
plt.close('all')
```

```{python}

```

```{python}
def density_filter(points, radius=1, min_neighbors=2, with_hist_plot=False):
    kdt = sp.spatial.KDTree(points)
    nn = kdt.query_ball_point(points, radius, return_length=True)
    if with_hist_plot:
        fig = plt.figure()
        plt.hist(nn, 200);
    return points[nn >= min_neighbors]

def merge_points(points, radius=0.75, niters=1, decimals=1):
    for i in tqdm(range(niters)):
        kdt = sp.spatial.KDTree(points)
        nn = kdt.query_ball_point(points, radius)
        points = np.array([points[xi].mean(0) if len(xi) else p 
                           for p,xi in zip(points,nn)])
        #points = points[nn].mean(axis=1)
        binned_points = np.unique(points.round(decimals), axis=0)
    return binned_points
```

```{python}
# #kdt.query_ball_point?
```

```{python}
ridge_points =  merge_points(endpoints, radius=0.75, niters=10)
ridge_points0 = density_filter(endpoints, radius=3, with_hist_plot=True)
ridge_points2 = density_filter(ridge_points, radius=3, with_hist_plot=True)
```

```{python}
len(endpoints), len(ridge_points), len(ridge_points2)
```

```{python}
ax = project_points(ridge_points, img=final_image.max(0), ax=None, 
                    markersize=5,
                    alpha=0.75)
ax.figure
```

```{python}
ax = project_points(ridge_points0, 
                    img=final_image.max(0), ax=None, 
                    markersize=4,
                    alpha=0.5)
ax.figure
```

```{python}
ax = project_points(ridge_points2, 
                    img=final_image.max(0), ax=None, 
                    markersize=5,
                    alpha=0.75)
ax.figure
```

```{python}
w = napari.view_image(final_image)
w.add_points(endpoints, size=0.5, opacity=0.25, edge_color='m', face_color='red')
w.add_points(ridge_points, size=1, opacity=0.75, edge_color='blue', face_color='blue')
w.add_points(ridge_points2, size=1, opacity=1, edge_color='green', face_color='green')
#w.add_points(endpoints2, size=0.5, opacity=1, edge_color='red', face_color='red')
```

---

```{python}
def find_ridge_points(image, sigma, niter=100, tol=5e-3):
    H,g  = hessian_by_dog(final_image, 
                          sigma=np.array((sigma/scale[0],sigma,sigma)), 
                          rel_scale=scale,
                          return_gradient=True) # RC order by default

    # weight by sigma to keep vectors in approximately the same range 
    # for different spatial scales
    g = sigma*np.stack(g,axis=3) 

    lams,Vf = hessian_eigen_decomp(H)
    
    sato = barebone_sato(lams)
    threshold = threshold_li(sato[sato>0])#*sigma**0.5
    mask = remove_small_objects(sato > threshold, min_size=int(sigma*64))    
    
    VV = np.einsum('...ij,...jk', Vf[...,1:], np.einsum('...ji', Vf[...,1:]))
    VVg = np.einsum('...ij,...j->...i', VV, g)
    del VV
    
    VVg_mag = np.linalg.norm(VVg,axis=-1)
    
    pth = np.percentile(VVg_mag, 99)
    VVg_clipped = VVg/pth
    VVg_clipped[VVg_mag>pth] /= VVg_mag[VVg_mag>pth][:,None]/pth
    
    pts = np.array(np.where(mask)).T
    endpoints = calc_trajectory_multi2(VVg_clipped,
                                       pts, 
                                       n_iter=niter, 
                                       tol=0.001, 
                                       h=0.25, 
                                       gamma=0.99,
                                       agg_alpha=0.5)
    merged = merge_points(endpoints, radius=0.5,  niters=1)
    return density_filter(merged, radius=1.5, min_neighbors=2)
```

```{python}
# %time ridge_12 = find_ridge_points(final_image, 12.0, niter=1200)
```

```{python}
# %time ridge_6 = find_ridge_points(final_image, 6.0, niter=600)
```

```{python}
# %time ridge_3 = find_ridge_points(final_image, 3.0, niter=300)
```

```{python}
# %time ridge_1d5 = find_ridge_points(final_image, 1.5, niter=150)
```

```{python}
_=1
```

```{python}
w = napari.view_image(final_image)
w.add_points(ridge_1d5, size=0.5, opacity=0.5, edge_color='red', face_color='red')
w.add_points(ridge_3, size=0.5, opacity=0.5, edge_color='magenta', face_color='m')
w.add_points(ridge_6, size=0.5, opacity=0.5, edge_color='blue', face_color='blue')
w.add_points(ridge_12, size=0.5, opacity=0.5, edge_color='cyan', face_color='cyan')

```

```{python}
#sigmas = 2**np.arange(0, 4, 0.5)
#sigmas
```

```{python}
sigmas = [1.5, 3, 6, 12]
```

```{python}
id2sigma = {i+1:sigma for i, sigma in enumerate(sigmas)} # shift by one, so that zero doesn't correspond to a cell
sigma2id = {sigma:i+1 for i, sigma in enumerate(sigmas)}
```

```{python}
sato_coll = {}
for sigma in tqdm(sigmas):
    #astro.morpho.sato3d is newer and uses tensorflow (if it's installed)
    #optimally, the two variants of sato3d should be merged
    sato = astro.morpho.sato3d(final_image, (sigma/scale[0], sigma,sigma), hessian_variant='gradient_of_smoothed', do_brightness_correction=False, return_vectors=False)
    sato_coll[sigma] = (sato*sigma**2)*(final_image > 0)
```

```{python}
masks = {}
for sigma in tqdm(sigmas):
    sato = sato_coll[sigma]
    threshold = threshold_li(sato[sato>0])*sigma**0.5
    masks[sigma] = remove_small_objects(sato > threshold, min_size=int(sigma*64))
```

```{python}
from ucats import masks as umasks
```

```{python}
masks[sigmas[-1]] = umasks.select_overlapping(masks[sigmas[-1]], soma_mask)
```

```{python}
for k in range(len(sigmas)-2,-1,-1):
    sigma = sigmas[k]
    masks[sigma] = umasks.select_overlapping(masks[sigma], 
                                             ndi.binary_dilation(masks[sigmas[k+1]], 
                                                                 iterations=5))
```

```{python}
sigma_sato = np.zeros(final_image.shape, dtype=int)
hout = np.zeros(final_image.shape)
mask_sum = np.zeros(final_image.shape, dtype=bool)

for sigma, sato in tqdm(sorted(sato_coll.items(), reverse=True)):
    hcurr = sato
    mask_sum = masks[sigma] | mask_sum
    mask = (hcurr > hout)*mask_sum # restrict search for optimal sigmas by the corresponding mask
    
    hout[mask] = hcurr[mask]
    sigma_sato[mask] = sigma2id[sigma]
```

```{python}
# w = napari.view_image(final_image)
# #napari.view_image(hout)
# w.add_image(sigma_sato)
```

```{python}

```

```{python}
# test_sigmas = ndi.map_coordinates(sigma_sato, ridge_6.T)
# len(test_sigmas), len(ridge_6)
# ridge_6r = ridge_6[test_sigmas == 6]
```

```{python}
sigmas
```

```{python}
res_ridges = {}
for ridge, sigma in zip([ridge_1d5, ridge_3, ridge_6, ridge_12], sigmas):
    #values = ndi.map_coordinates(sigma_sato, ridge.T, order=0)
    
    values = np.array([ndi.map_coordinates(sato_coll[sigma]*masks[sigma], ridge.T, order=1) 
              for sigma in sigmas])
    
    ksigma = np.argmax(values, axis=0)+1
    cond = ksigma == sigma2id[sigma]
    res_ridges[sigma] = ridge[cond]
```

```{python}
sigma2id
```

```{python}
w = napari.view_image(final_image)
w.add_points(res_ridges[1.5], name=1.5, size=0.5, opacity=0.5, edge_color='red', face_color='red')
w.add_points(res_ridges[3], name=3,size=0.5, opacity=0.5, edge_color='magenta', face_color='m')
w.add_points(res_ridges[6], name=6,size=0.5, opacity=0.5, edge_color='blue', face_color='blue')
w.add_points(res_ridges[12], name=12,size=0.5, opacity=0.5, edge_color='cyan', face_color='cyan')
```

```{python}
# %matplotlib qt
```

```{python}
show_field2d(VVg_clipped[40][...,1:]/4, final_image[40], scale=10, weights=sato[40])
```

```{python}
show_field2d(VVg[40][...,1:]/VVg_mag_max, final_image[40], scale=10, weights=sato[40])
plt.title('new')
```

------------------------

```{python}

```
